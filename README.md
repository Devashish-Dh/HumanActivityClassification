# HumanActivityClassification
Human body tracking and action recognition using neural networks : Project

ABSTRACT

The idea of computers being able to "look” , “see" and understand human actions has been central in the field of computer vision. However, the physical hardware, software and computing limitations have made it a challenge to do so effectively in a robust manner. The traditional approach of using Machine Learning has an alternative in Deep Learning models. The project aims to build such a deep learning-based model. The project is divided into three stages, one, to capture time series data of the human action using a camera and use BlazePose, a lightweight convolutional neural network architecture for human pose estimation that is tailored for real-time inference. The key-points obtained from the model are recorded and saved to use as training data for certain actions performed by the subject. Second, the LSTM is built and trained on the generated data, the weights are saved and this brings us to stage three, to use the time series data to estimate the action performed by applying the trained sequential LSTM Model.

